import keras,os
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPool2D , Flatten
from keras.preprocessing.image import ImageDataGenerator
import numpy as np
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam
from keras.preprocessing import image
from keras.preprocessing.image import img_to_array
from keras.preprocessing.image import ImageDataGenerator, load_img
import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator(
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest')


trdata = ImageDataGenerator()
traindata = trdata.flow_from_directory(directory="D:/ME/research/mamogram_and_thermograms/VGG16/training_set",target_size=(224,224))
tsdata = ImageDataGenerator()
testdata = tsdata.flow_from_directory(directory="D:/ME/research/mamogram_and_thermograms/VGG16/test_set", target_size=(224,224))

VGG = keras.applications.VGG16(input_shape=(224,224,3),include_top=False, weights ='imagenet')
for layer in VGG.layers[:7]:
    layer.trainable = False
    
x = VGG.output

x=Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu")(x) #(VGG.output)
x=MaxPool2D(pool_size=(2,2),strides=(2,2))(x)
x=Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu")(x)
x=Conv2D(filters=512, kernel_size=(3,3), padding="same", activation="relu")(x)
x=Conv2D(filters=256, kernel_size=(3,3), padding="same", activation="relu")(x)
x=Conv2D(filters=128, kernel_size=(3,3), padding="same", activation="relu")(x)
x=MaxPool2D(pool_size=(2,2),strides=(4,4))(x)

# Flatten the output
x= Flatten()(x)

# Add two fully connected lay
x= Dense(512, activation='relu')(x)
#x=Dropout(0.5))
x=Dense(512, activation='relu')(x)

# Output layer for Cats and Dogs classification
prediction= Dense(units=2, activation='softmax')(x)

model = keras.Model(inputs = VGG.input , outputs= prediction)
model.summary()
model.compile(optimizer='adam',loss =keras.losses.categorical_crossentropy,metrics=['accuracy'])

# Train the model
hist = model.fit_generator(steps_per_epoch = 100, generator = traindata, validation_data=testdata,validation_steps=10, epochs=10)
model.save('vggclf.h5')    

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score

# Generate predictions for the test data
y_pred = model.predict(testdata)

# Get the true labels for the test data
y_true = np.argmax(testdata.classes, axis=1)

print(confusion_mtx)
confusion_mtx = confusion_matrix(y_true, y_pred_labels, labels=[0, 1])
print("Confusion Matrix:")
print(confusion_mtx)

accuracy = accuracy_score(y_true, y_pred_labels)
print("Accuracy:", accuracy)

# Compute and print precision
precision = precision_score(y_true, y_pred_labels)
print("Precision:", precision)

# Compute and print recall
recall = recall_score(y_true, y_pred_labels)
print("Recall:", recall)

# Compute and print F1 score
f1 = f1_score(y_true, y_pred_labels)
print("F1 Score:", f1)

# Specificity can be computed as follows:
tn, fp, fn, tp = confusion_mtx.ravel()
specificity = tn / (tn + fp)
print("Specificity:", specificity)

# Print a classification report
class_report = classification_report(y_true, y_pred_labels, target_names=class_labels)
print(class_report)

# Save or display the plot
plt.savefig('confusion_matrix.png')  # Save the plot as an image
plt.show()  # Display the plot
